![Python](https://img.shields.io/badge/python-3.10-blue)


- [ü¶úÔ∏èüîó Langchain "converse com..." Demo](#Ô∏è-langchain-converse-com-demo)
  - [Introdu√ß√£o](#introdu√ß√£o)
  - [Instala√ß√£o](#instala√ß√£o)
  - [Main](#main)
  - [Ask Document / Talk With Your Documents](#ask-document--talk-with-your-documents)
  - [Site QA / Talk With Your Website](#site-qa--talk-with-your-website)
  - [Duck-Duck-go](#duck-duck-go)

# ü¶úÔ∏èüîó Langchain "converse com..." Demo
O objetivo do projeto √© explorar algumas fun√ß√µes do langchain, comparar alguns resultados com modelos menores (e.g. mDeBERTa) e testar uma maneira mais barata de usar o ChatGPT para fazer buscas em sites.

## Introdu√ß√£o
Os modelos utilizados nesse projeto foram o ChatGPT e o [mDeBERTa](https://huggingface.co/timpal0l/mdeberta-v3-base-squad2). Este √∫ltimo apenas para responder perguntas com base em documentos fornecidos  (_question answering_).

Praticamente todas as funcionalidades seguem o j√° conhecido fluxo de QA : 1. Os textos s√£o quebrados em peda√ßos e transformados em embeddings. 2. Um indexador cria os √≠ndices para esses embeddings e o armazena no que chamamos de base de conhecimento (_knowledge base_).  3. Quando uma pergunta √© feita pelo usu√°rio, uma busca sem√¢ntica √© feita na nossa base de conhecimento que retorna os trechos mais prov√°veis de conter a resposta. 4. Esses trechos s√£o ent√£o enviados junto a pergunta do usu√°rio para modelo QA que retorna a resposta final ao usu√°rio. A imagem abaixo ilustra esse fluxo.

<div style="text-align: center;">
    <img src="assets\qa_flow.png" alt="QA flow">
</div>

Utilizei um sistema id√™ntico a esse para responder perguntas com base em um site fornecido pelo usu√°rio, nesse cen√°rio o documento que comp√µe o embedding √© o conte√∫do do link que o usu√°rio fornece. Com exce√ß√£o do Duck Duck Go. Neste caso √© feito uma busca na web utilizando a API do Duck Duck Go com a restri√ß√£o de que o resultado da busca deve ter o mesmo dom√≠nio informado pelo usu√°rio.

## Instala√ß√£o
Neste projeto fizemos uso do pipenv e do docker. Se n√£o tiver o docker instalado aqui est√£o os links para instala√ß√£o para [linux](https://docs.docker.com/desktop/install/linux-install/) e [windows](https://docs.docker.com/desktop/install/windows-install/). Se j√° tiver o docker instalado √© s√≥ fazer no terminal:

```console
docker-compose build
```
o processo demora um pouco quando executado pela primeira vez. Em seguida:

```console
docker-compose up
```
Se tudo correr, bem aparecer√° a mensagem "_You can now view your Streamlit app in your browser._". Ent√£o √© s√≥ digitar no navegador: "<http://localhost:8001/>" para acessar o aplicativo.

## Main
A p√°gina inicial (main) √© simplesmente o chatgpt-3.5 turbo. Basta inserir sua OpenAI Key para poder utilizar.


## Ask Document / Talk With Your Documents
Na p√°gina _ask Document_ √© poss√≠vel conversar com esse LEIAME que j√° teve √≠ndexes gerados e est√° dispon√≠vel para os modelos. Ao final da pergunta a fonte no qual a resposta foi retirada √© informada.

Voc√™ tamb√©m pode enviar documentos de at√© 200mb no formato .txt ou .pdf. Para fazer o upload √© necess√°rio selecionar um ou mais modelo embedding. O "HuggingFace embedding" ser√° usado para gerar os embeddings que ser√£o indexados e estar√£o dispon√≠vel para o mDeBERTa. E o "OpenAi embedding" ficar√° dispon√≠vel para o ChatGPT.

Voc√™ tamb√©m pode fazer o upload de v√°rios documentos de uma s√≥ vez. Ap√≥s submeter corretamente os arquivos, j√° √© poss√≠vel conversar com os documentos, tanto os novos quanto os antigos.

## Site QA / Talk With Your Website
Nesta se√ß√£o o usu√°rio deve fornecer um url antes de fazer perguntas. Por padr√£o ser√° feito o scrape apenas da p√°gina fornecida, mas o usu√°rio tem a op√ß√£o de selecionar "_Entire Website_" (Todo o site). O scrape de todo o site ser√° feito. Tenha em mente que esta a√ß√£o pode ter um custo elevado, visto que ser√° feito o embedding de todo o site utilizando o modelo "text-embedding-ada-002" da OpenAI.

Ap√≥s inserir um url v√°lido e decidir se quer ou n√£o utilizar todo o site, voc√™ pode fazer perguntas para seu URL.

## Duck-Duck-go
O alto custo de ler um site inteiro, como mencionado na se√ß√£o anterior, pode, a priori, ser contornado utilizando um modelo embedding gratuito. Por exemplo, poder√≠amos utilizar o modelo usado para o mDeBERTa: "intfloat/multilingual-e5-base".

Por√©m eu decidi fazer este teste utilizando o Duck-Duck-Go Search. Como n√£o temos um modelo inteligente como o ChatGPT para traduzir as informa√ß√µes automaticamente, temos que verificar antes se o idioma do site informado e o idioma que o usu√°rio escreveu a pergunta s√£o o mesmo e, caso necess√°rio, traduzir a pergunta do usu√°rio para o mesmo idioma do site.

O fluxo ent√£o pode ser descrito nos seguintes passos. 1. traduz a query do usu√°rio, caso necess√°rio. 2. utiliza a API do Duck Duck Go para fazer a pergunta do usu√°rio com a seguinte restri√ß√£o: a resposta deve estar no mesmo dom√≠nio informado pelo usu√°rio. 3. Passamos os trechos com as respostas encontradas pelo Duck Duck Go e a pergunta do usu√°rio para o ChatGPT. 4. O modelo se encarrega de encontrar a resposta e traduzir de volta, se necess√°rio, para o idioma do usu√°rio.

<div style="text-align: center;">
    <img src="assets\duck_go_flow.png" alt="Duck Go flow">
</div>

Note que dessa forma, n√£o geramos os √≠ndices sem√¢nticos. O pr√≥prio Duck Duck Go se encarrega de fazer a busca pela informa√ß√£o que desejamos. Embora o modelo pare√ßa funcionar bem, ele √© muito lento. Isso acontece porque n√£o √© criada uma base de conhecimento com √≠ndices para fazermos a busca sem√¢ntica. Ou seja, a cada pergunta o fluxo inteiro √© refeito.

<style>
    body {
        text-align: justify;
    }
</style>